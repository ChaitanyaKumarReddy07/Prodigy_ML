
CI/CD Process(Jenkines)

What is Jenkins and what is its purpose:
Jenkins is an open source automation sever used for continuous integration and 
continuous delivery (CI/CD). It automates the building, testing, and deployment 
of software.
What is the difference between CI and CD Process:
CI focuses on Build and test,where CD focuses on release and deploy.
What is meant by JenkinesFile:
A Jenkinsfile is a text file that defines a Jenkins Pipeline.It's written in 
Groovy syntax.This file specifies the entire build process,including stages,
actions and configurations.
How do you create a Jenkins pipeline:
Jenkins pipelines can be created by writing a Jenkinsfile, which is a text file 
that contains the definition of a pipeline using the Groovy scripting language.
Explain the difference between Jenkins Freestyle project and Jenkins Pipeline:
Freestyle projects are traditional Jenkins projects configured through a UI,
while Pipelines are defined as code using a Jenkinsfile, allowing for more complex
and customizable workflows.
"Master" will continue to perform basic operations and serve the user 
interface.
"slave" will do the heavy lifting.Let us assume we have 100 bills in our 
master server.If you build all the 100bills in the master server there 
might be some performance issues for the instance.
The main advantage of this master slave concept is Jenkines is to 
distribute the workload to the slaves, so the slaves can share them work 
from the master and master is going to assign the jobs to slaves.
How do you handle security in Jenkins:
Security in Jenkins can be managed through various means such as user 
authentication, authorization strategies, project-based security, and 
plugins like Role-based Authorization Strategy.
How do you troubleshoot a failed Jenkins build:
Troubleshooting a failed Jenkins build involves checking build logs, identifying 
error messages, examining the configuration, verifying permissions, and reviewing 
changes that might have caused the failure.
"Plugins":
"ThinBackup" is used simply backs up the global and job specific configurations.
"Deploy to container" This plugin takes a war/ear file and deploys that to a 
running remote application server at the end of a build.
"Nexus" plugin is used  for artifactory storage 
How do you handle Job dependencies in Jenkines:
1.Parameter Builds
2.Build Triggers
3.Plugins
4.Pipeline Jobs
5.Some External Tools and Scripts

How do you create a backup and copy files in Jenkines:
In Jenkins, you can create backups by copying the Jenkins home directory, which 
contains all configurations, job definitions, and build history. To do this, stop 
Jenkins, copy the entire contents of the Jenkins home directory to a backup 
location, and restart Jenkins.
To copy files in Jenkins, you can use various plugins or execute shell commands in
your build process. Plugins like "Copy Artifact Plugin" can help copy files 
between jobs within the Jenkins.
How can you copy jenkines from one server to another:
Move a job from one installation of jenkines to another by copying the 
corresponding job directory.Create a copy of an exsiting job by making a clone of 
a job directory by a different name.Then rename the exsiting job by renaming a
directory.This way we can do it.

CI/CD pipeline automates software delivery process. It includes continuous
 integration, testing, deployment, and monitoring.
In our CI/CD Pipeline stages:
Source code management (SCM) we use Gitmwm
for build we are using maven
Continuous integration (CI) we use Jenkins
Automated testing we use Selenium
Containerization we use Docker
Continuous deployment (CD) we use Ansible
Infrastructure as code (IaC) tools like Terraform, CloudFormation
Monitoring tools like Prometheus

Explain the concept of blue-green deployment:
Blue-green deployment involves maintaining two identical production environments, 
allowing seamless switching between them. This helps in deploying updates without 
downtime, reducing risk by verifying the new version in a live environment before
routing traffic to it.	 
How do you utilize Docker within your CI/CD pipeline:
Docker enables containerization, ensuring consistent environments across 
development, testing, and production stages. Within the pipeline, I'd create 
Docker images, run tests in isolated containers, and deploy applications within 
Docker containers to streamline the deployment process.

Explain the importance of artifact management within the CI/CD pipeline:
Artifact management involves storing and versioning build artifacts for future 
reference .we used artifact repositories like Nexus to store artifacts, ensuring 
traceability and easy access for deployment.
Deployment Rollback:
If a critical bug causes a deployment failure in production, my immediate action 
would be to initiate a rollback to the last stable version. Simultaneously, I'd
gather the development and testing teams to identify the root cause, fix the issue
thoroughly test it in a staging environment, and redeploy it after ensuring its 
stability.
How do you optimize the CI/CD pipeline for better efficiency and reliability:
I'd regularly review pipeline performance, analyze metrics from team members to 
identify areas for improvement. This might involve optimizing build times,
refining testing strategies and frameworks to enhance pipeline efficiency and 
reliability.

"PIPELINE SYNTAX"
pipeline{
Agent any
Stages{
stage(stage-1)
steps{
echo"hello world"
}
}
}

There are mainly two types of pipelines:
Declarative Pipeline:
Uses a predefined structure and simplifies the creation of complex pipelines. It 
is written using a declarative syntax with specific blocks like pipeline, stages,
and steps
     pipeline {
         agent any
         stages {
             stage('Build') {
                 steps {
                     
                 }
             }
             stage('Test') {
                 steps {
                     
                 }
             }
             stage('Deploy') {
                 steps {
                    
                 }
             }
         }
     }
Scripted Pipeline:
Uses Groovy scripting language and allows for more flexibility and control by 
writing code directly. It involves using node blocks to allocate tasks to specific
 nodes and scripting the entire pipeline flow.
     node {
         stage('Build') {
             // Perform build tasks here
         }
         stage('Test') {
             // Perform testing tasks here
         }
         stage('Deploy') {
             // Perform deployment tasks here
         }
     }
